# Projects

<img src="https://bit.ly/2VnXWr2" alt="Ironhack Logo" width="100"/>

# Data_Wrangling_Shark_Attacks

*Julia Zimpel*

*Full-Time Data Analytics 2020-08, Campus Berlin & 23 Aug. 2020*

## Content

**[Project Description]**

This project seeks to demonstrate data wrangling skills in Python. The task is to perform data cleaning operations on a dataset on shark attacks. The main language utilized is Python with additional resources of Pandas and Regex. In the process, already some initial hypotheses about data corelations are tested.


**[Questions & Hypotheses]**

My analysis aims to provide answers to the following questions:

1. What data is unnecessary and can be ommited for better viewing purposes?
2. How can different data types be aligned to be more easily managable? 
3. What factors correlate with shark attacks? (initial hypotheses)

**[Dataset]**

The following dataset is used in the project:

File Path: Projects/GSAF5.csv
Columns: 24
Rows: 5992
Entries: 143,808

**[Database]**

The database consists of only one table:

Source: kaggle.com
Original Name: "sharkoriginal.csv". 

**[Workflow]**

First the data is analyzed to arrive at a basic understanding.
Then hypthoses are built and tested.
At last operations such as deleting columns and rows, as well as filtering are performed. 

**[Organization]**

The project adheres to the following file structure:

1. README
2. shark_attacks.ipynb
3. gitignore

The file shark_attacks.ipynb is structured as below:

1. Import all necessary data and tools
2. Understand the dataset
3. Data Wrangling


**[Repository]**

*https://github.com/Yulizzz123/Projects/Data_Wrangling_Shark_Attacks*  

