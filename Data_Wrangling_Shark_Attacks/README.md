# Projects

<img src="https://bit.ly/2VnXWr2" alt="Ironhack Logo" width="100"/>


# Data_Wrangling_Shark_Attacks

*Julia Zimpel*

*Full-Time Data Analytics 2020-08, Campus Berlin & 23 Aug. 2020*


## Content

\
**[Project Description]**

This project seeks to demonstrate data wrangling and analysis skills in Python. The task is to perform data cleaning and sorting operations on a dataset on shark attacks. The main language utilized is Python with additional resources of Pandas and Regex. In the process, hypotheses are tested and validated or dismissed.

\
**[Questions & Hypotheses]** 

My analysis aims to provide answers to the following questions:

1. What data is unnecessary and can be ommited for better viewing purposes?
2. How can different data types be aligned to be more easily managable? 
3. What is the relation between certain factors and shark attacks? 

\
**[Dataset]**

The following dataset is used in the project:

File Path: Projects/GSAF5.csv
Columns: 24
Rows: 5992
Entries: 143,808

\
**[Database]**

The database consists of only one table:

Source: kaggle.com
Original Name: "sharkoriginal.csv". 

\
**[Workflow]**

First the data is analyzed to arrive at a basic understanding.
Then hypthoses are built and tested.
At last operations such as deleting columns and rows, as well as filtering are performed. 

\
**[Organization]**

The project adheres to the following file structure:

1. README
2. main.ipynb
3. GSAF5.csv
4. gitignore

The file "main.ipynb" is structured as below:

1. Import all necessary data and tools
2. Understand the dataset
3. Data wrangling and sorting
4. Arriving at preliminary findings and conclusions

\
**[Repository]**
*https://github.com/Yulizzz123/Projects/Data_Wrangling_Shark_Attacks*  

